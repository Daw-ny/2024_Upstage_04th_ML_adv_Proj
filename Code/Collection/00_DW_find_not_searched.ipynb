{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **🏠 네이버 부동산 크롤링**\n",
    "> 크롤링한 값들 중에 검색이 되지 않은 값을 직접 검색하기 위해 나열\n",
    "\n",
    "## Contents\n",
    "- Library Import\n",
    "- Data Load\n",
    "- Crawling of Naver real estate home page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Library Import\n",
    "- 필요한 라이브러리를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "fe = fm.FontEntry(\n",
    "    fname=r'/usr/share/fonts/truetype/nanum/NanumGothic.ttf', # ttf 파일이 저장되어 있는 경로\n",
    "    name='NanumBarunGothic')                        # 이 폰트의 원하는 이름 설정\n",
    "fm.fontManager.ttflist.insert(0, fe)              # Matplotlib에 폰트 추가\n",
    "plt.rcParams.update({'font.size': 10, 'font.family': 'NanumBarunGothic'}) # 폰트 설정\n",
    "plt.rc('font', family='NanumBarunGothic')\n",
    "import seaborn as sns\n",
    "\n",
    "# utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "\n",
    "# Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_info = pd.read_csv('../Data/아파트정보.csv')\n",
    "apt_area = pd.read_csv('../Data/아파트면적정보.csv')\n",
    "\n",
    "apt_info2 = pd.read_csv('../Data/아파트정보2.csv')\n",
    "apt_area2 = pd.read_csv('../Data/아파트면적정보2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = pd.concat([apt_info, apt_info2])\n",
    "aa = pd.concat([apt_area, apt_area2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 데이터를 load 하겠습니다. 경로는 환경에 맞게 지정해주면 됩니다.\n",
    "train = pd.read_csv('../Data/KOREAN_train4.csv')\n",
    "test = pd.read_csv('../Data/KOREAN_test4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['계약년월'] >= 201701]\n",
    "train = train[train['target'] > 6111.11]\n",
    "train[['연', '월']] = train['계약년월'].apply(lambda x: list(divmod(x, 100))).tolist()\n",
    "\n",
    "# 정규표현식 패턴 생성\n",
    "excluded_apts = ['AirPalace', 'SRvill', '경동팰리스힐', '대길B', '썬앤빌', '재선주택', '코원']\n",
    "\n",
    "# go\n",
    "pattern = '|'.join(excluded_apts)\n",
    "\n",
    "# '열이름' 열에서 패턴이 있는지 확인하여 새로운 열 추가\n",
    "train['is_아파트'] = np.where(train['아파트명'].str.contains(pattern), 1, 0)\n",
    "\n",
    "train = train[train['is_아파트'] == 0]\n",
    "\n",
    "train = train.drop(columns='is_아파트')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시구동으로 시군구를 나누기\n",
    "train[['시', '구', '동']] = train['시군구'].str.split(expand = True)\n",
    "test[['시', '구', '동']] = test['시군구'].str.split(expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 겹치는 동, 아파트명 제거\n",
    "dap = train[['동', '아파트명']].drop_duplicates(['아파트명']).reset_index()\n",
    "dap2 = test[['동', '아파트명']].drop_duplicates(['아파트명']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동 아파트명 생성하기\n",
    "dap['동아파트명'] = dap['동'] + ' ' + dap['아파트명']\n",
    "dap2['동아파트명'] = dap2['동'] + ' ' + dap2['아파트명']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test에 있는 동아파트명 \n",
    "dap_merge = pd.concat([dap['동아파트명'], dap2['동아파트명']], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동아파트명 겹치지 않게 뽑기\n",
    "d = dap_merge.reset_index()['동아파트명']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 안된 동아파트명 가져오기\n",
    "not_searched = ai['동아파트명'][ai['세대수'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동아파트명 새로운 리스트로 불러오기\n",
    "new_list = pd.concat([not_searched, d[~d.isin(ai['동아파트명'])]]).reset_index()['동아파트명']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "new_list.to_csv('../Data/검색안된아파트.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
